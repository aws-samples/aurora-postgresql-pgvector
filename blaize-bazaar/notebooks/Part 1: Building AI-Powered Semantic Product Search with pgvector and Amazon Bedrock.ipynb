{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Building AI-Powered Semantic Product Search with pgvector and Amazon Bedrock\n",
    "### Configuration, Vector Embeddings and Data Ingestion\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "2. [Architecture](#Architecture)\n",
    "3. [Setup](#Setup)\n",
    "4. [Load Product Data](#Load-Product-Data)\n",
    "5. [Generate Embeddings](#Generate-Embeddings)\n",
    "6. [Store in PostgreSQL](#Store-in-PostgreSQL)\n",
    "\n",
    "## Background\n",
    "\n",
    "This lab demonstrates how Blaize Bazaar implements intelligent product discovery using semantic search. Our solution enables customers to find products using natural language queries, understanding context beyond simple keyword matching.\n",
    "\n",
    "Key components of Blaize Bazaar's search system:\n",
    "\n",
    "- **Smart Search**: Amazon Titan Embeddings converts customer queries into semantic vectors\n",
    "- **Efficient Storage**: Aurora PostgreSQL with pgvector powers our product catalog\n",
    "- **Vector Similarity**: Amazon Bedrock and pgvector work together to match customer queries with relevant products using cosine similarity\n",
    "\n",
    "## Blaize Bazaar's Product Data\n",
    "\n",
    "- Source: [Amazon Products Dataset 2023](https://www.kaggle.com/datasets/asaniczka/amazon-products-dataset-2023-1-4m-products/data)\n",
    "- Catalog Size: **21,704** products across multiple categories\n",
    "- Curated Selection: Top and emerging products per category\n",
    "- Quality Focus: Products with verified customer ratings\n",
    "\n",
    "## Product Catalog Design\n",
    "\n",
    "Blaize Bazaar's `bedrock_integration.product_catalog` table structure:\n",
    "\n",
    "| **Column**          | **Data Type**    | **Constraints** | **Description** | \n",
    "| ------              | ------           | ------          | ------          | \n",
    "| productId           | VARCHAR (255)    | NOT NULL, PK    | Unique identifier for each product\n",
    "| product_description | TEXT             |                 | Detailed description of products\n",
    "| imgurl              | TEXT             |                 | URL to the product image\n",
    "| producturl          | TEXT             |                 | URL to the product page\n",
    "| stars               | NUMERIC          |                 | Product rating (out of 5)\n",
    "| reviews             | INT              |                 | Number of reviews for the product\n",
    "| price               | NUMERIC          |                 | Price of the product\n",
    "| category_id         | INT              |                 | Identifier for the product category\n",
    "| isbestseller        | BOOLEAN          |                 | Flag indicating if the product is a bestseller\n",
    "| boughtinlastmonth   | INT              |                 | Number of units sold in the last month\n",
    "| category_name       | VARCHAR (255)    |                 | Name of the product category\n",
    "| quantity            | INT              |                 | Available quantity of the product\n",
    "| embedding           | VECTOR (1024)    |                 | Vector embeddings for semantic search\n",
    "\n",
    "### Search Optimization\n",
    "The table has two indexes:\n",
    "\n",
    "- Primary Key: B-tree index on `productId` - Facilitates fast product lookup\n",
    "- Vector Search: HNSW index on `embedding` column - Facilitates advanced similarity search\n",
    "    - Parameters: `m=16, ef_construction=64`\n",
    "    - Optimization: Cosine similarity search\n",
    "\n",
    "## Embeddings Model\n",
    "\n",
    "Blaize Bazaar uses [Amazon Titan Text Embeddings V2](https://aws.amazon.com/bedrock/titan/)\n",
    "\n",
    "## Technical Architecture\n",
    "\n",
    "![Building AI-Powered Semantic Product Search with pgvector and Amazon Bedrock](../static/Product_Catalog.png)\n",
    "\n",
    "**Customer Search Experience**:\n",
    "\n",
    "1. Convert product descriptions to embeddings (Amazon Bedrock)\n",
    "2. Store and index product information efficiently (Aurora PostgreSQL + pgvector)\n",
    "3. Convert customer's search queries to embeddings\n",
    "4. Return personalized product recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required Python packages. You can safely disregard the warning *\"Note: you may need to restart the kernel to use updated packages.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all the required prerequisite libraries in a single command to better handle dependencies\n",
    "%pip install setuptools==65.5.0 httpx>=0.25.0 \"psycopg[binary]\" pgvector pandarallel boto3 tqdm \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "print(\"Required libraries setup complete âœ… \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aurora PostgreSQL Database Setup\n",
    "\n",
    "Set up PostgreSQL with the pgvector extension and create our product catalog table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get database credentials from Secrets Manager\n",
    "client = boto3.client('secretsmanager')\n",
    "response = client.get_secret_value(SecretId='apg-pgvector-secret-RIV')\n",
    "database_secrets = json.loads(response['SecretString'])\n",
    "\n",
    "# Set up database connection parameters\n",
    "dbhost = database_secrets['host']\n",
    "dbport = database_secrets['port']\n",
    "dbuser = database_secrets['username']\n",
    "dbpass = database_secrets['password']\n",
    "\n",
    "def setup_database():\n",
    "    \"\"\"Set up database schema and tables\"\"\"\n",
    "    conn = psycopg.connect(\n",
    "        host=dbhost,\n",
    "        port=dbport,\n",
    "        user=dbuser,\n",
    "        password=dbpass,\n",
    "        autocommit=True\n",
    "    )\n",
    "\n",
    "    # Enable vector extension\n",
    "    conn.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    register_vector(conn)\n",
    "\n",
    "    # Create schema\n",
    "    conn.execute(\"CREATE SCHEMA IF NOT EXISTS bedrock_integration;\")\n",
    "\n",
    "    # Drop existing table if needed\n",
    "    conn.execute(\"DROP TABLE IF EXISTS bedrock_integration.product_catalog;\")\n",
    "\n",
    "    # Create products table\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS bedrock_integration.product_catalog (\n",
    "        \\\"productId\\\" VARCHAR(255) PRIMARY KEY,\n",
    "        product_description TEXT,\n",
    "        imgurl TEXT,\n",
    "        producturl TEXT,\n",
    "        stars NUMERIC,\n",
    "        reviews INT,\n",
    "        price NUMERIC,\n",
    "        category_id INT,\n",
    "        isbestseller BOOLEAN,\n",
    "        boughtinlastmonth INT,\n",
    "        category_name VARCHAR(255),\n",
    "        quantity INT,\n",
    "        embedding vector(1024)\n",
    "    );\n",
    "    \"\"\")\n",
    "\n",
    "    # Create HNSW index\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE INDEX IF NOT EXISTS product_catalog_embedding_idx \n",
    "    ON bedrock_integration.product_catalog \n",
    "    USING hnsw (embedding vector_cosine_ops);\n",
    "    \"\"\")\n",
    "\n",
    "    print(f\"Connection info: host={dbhost}, port={dbport}, user={dbuser}\")\n",
    "    print(\"Database setup complete âœ…\")\n",
    "    conn.close()\n",
    "\n",
    "setup_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Product Catalog Data\n",
    "\n",
    "Load and preprocess the product catalog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load product data\n",
    "print(\"Loading product data...\")\n",
    "df = pd.read_csv('../datasets/product_catalog.csv')\n",
    "\n",
    "# Clean up missing values\n",
    "df = df.dropna(subset=['product_description'])\n",
    "df = df.fillna({\n",
    "    'stars': 0,\n",
    "    'reviews': 0,\n",
    "    'price': 0,\n",
    "    'category_id': 0,\n",
    "    'isbestseller': False,\n",
    "    'boughtinlastmonth': 0,\n",
    "    'category_name': 'Unknown',\n",
    "    'quantity': 0\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(df)} products\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Embeddings\n",
    "\n",
    "Generate embeddings using Amazon Bedrock's Titan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run time: ~ 3 mins\n",
    "def generate_embedding(text):\n",
    "    \"\"\"Generate embedding for a single text using Amazon Titan Text v2\"\"\"\n",
    "    try:\n",
    "        payload = json.dumps({'inputText': text})\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            body=payload,\n",
    "            modelId='amazon.titan-embed-text-v2:0',\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        return response_body.get(\"embedding\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Initialize parallel processing\n",
    "print(\"\\nGenerating embeddings for product descriptions...\")\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=10)\n",
    "\n",
    "# Generate embeddings\n",
    "df['embedding'] = df['product_description'].parallel_apply(generate_embedding)\n",
    "\n",
    "print(\"\\nCompleted embedding generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store in Database\n",
    "\n",
    "Store the products and their embeddings in Aurora PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run time: ~ 2 mins\n",
    "def store_products():\n",
    "    \"\"\"Store products in database with batch processing and statistics\"\"\"\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    batch_size = 1000\n",
    "\n",
    "    conn = psycopg.connect(\n",
    "        host=dbhost,\n",
    "        port=dbport,\n",
    "        user=dbuser,\n",
    "        password=dbpass,\n",
    "        autocommit=True\n",
    "    )\n",
    "\n",
    "    print(f\"Storing products in database... Total rows to process: {len(df)}\")\n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            batches = []\n",
    "            total_processed = 0\n",
    "\n",
    "            # Process data in batches\n",
    "            for i, (_, row) in enumerate(df.iterrows(), 1):\n",
    "                batches.append((\n",
    "                    row['productId'],\n",
    "                    row['product_description'],\n",
    "                    row['imgurl'],\n",
    "                    row['producturl'],\n",
    "                    row['stars'],\n",
    "                    row['reviews'],\n",
    "                    row['price'],\n",
    "                    row['category_id'],\n",
    "                    row['isbestseller'],\n",
    "                    row['boughtinlastmonth'],\n",
    "                    row['category_name'],\n",
    "                    row['quantity'],\n",
    "                    row['embedding']\n",
    "                ))\n",
    "\n",
    "                # When batch size is reached or at the end, process the batch\n",
    "                if len(batches) == batch_size or i == len(df):\n",
    "                    batch_start = time.time()\n",
    "\n",
    "                    cur.executemany(\"\"\"\n",
    "                    INSERT INTO bedrock_integration.product_catalog (\n",
    "                        \"productId\", product_description, imgurl, producturl,\n",
    "                        stars, reviews, price, category_id, isbestseller,\n",
    "                        boughtinlastmonth, category_name, quantity, embedding\n",
    "                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON CONFLICT (\"productId\") DO UPDATE \n",
    "                    SET \n",
    "                        product_description = EXCLUDED.product_description,\n",
    "                        imgurl = EXCLUDED.imgurl,\n",
    "                        producturl = EXCLUDED.producturl,\n",
    "                        stars = EXCLUDED.stars,\n",
    "                        reviews = EXCLUDED.reviews,\n",
    "                        price = EXCLUDED.price,\n",
    "                        category_id = EXCLUDED.category_id,\n",
    "                        isbestseller = EXCLUDED.isbestseller,\n",
    "                        boughtinlastmonth = EXCLUDED.boughtinlastmonth,\n",
    "                        category_name = EXCLUDED.category_name,\n",
    "                        quantity = EXCLUDED.quantity,\n",
    "                        embedding = EXCLUDED.embedding;\n",
    "                    \"\"\", batches)\n",
    "\n",
    "                    total_processed += len(batches)\n",
    "                    batch_time = time.time() - batch_start\n",
    "                    elapsed_total = time.time() - start_time\n",
    "\n",
    "                    # Calculate progress and estimated time remaining\n",
    "                    progress = (total_processed / len(df)) * 100\n",
    "                    avg_time_per_batch = elapsed_total / (total_processed / batch_size)\n",
    "                    remaining_batches = (len(df) - total_processed) / batch_size\n",
    "                    eta = remaining_batches * avg_time_per_batch\n",
    "\n",
    "                    print(f\"\\rProgress: {progress:.1f}% | Processed: {total_processed}/{len(df)} rows | \"\n",
    "                          f\"Batch time: {batch_time:.2f}s | ETA: {eta:.0f}s\", end=\"\")\n",
    "\n",
    "                    batches = []\n",
    "\n",
    "            print(\"\\n\\nRunning VACUUM ANALYZE...\")\n",
    "            cur.execute(\"VACUUM ANALYZE bedrock_integration.product_catalog;\")\n",
    "\n",
    "            # Get final statistics\n",
    "            cur.execute(\"SELECT COUNT(*) FROM bedrock_integration.product_catalog\")\n",
    "            final_count = cur.fetchone()[0]\n",
    "\n",
    "            end_time = time.time()\n",
    "            total_time = end_time - start_time\n",
    "\n",
    "            print(\"\\nðŸ“Š Data Loading Statistics:\")\n",
    "            print(f\"âœ“ Total rows loaded: {final_count:,}\")\n",
    "            print(f\"âœ“ Total loading time: {total_time:.2f} seconds\")\n",
    "            print(f\"âœ“ Average time per row: {(total_time/len(df))*1000:.2f} ms\")\n",
    "            print(f\"âœ“ Average time per batch: {(total_time/(len(df)/batch_size)):.2f} seconds\")\n",
    "            print(\"\\nâœ… Products stored successfully in database\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error storing products: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Load data with embeddings into the table\n",
    "store_products()\n",
    "print(\"\\nPart 1 Complete: Setup and data loading finished! âœ…\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
