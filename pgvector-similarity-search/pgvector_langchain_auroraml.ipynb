{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Search with pgvector and Amazon Aurora PostgreSQL\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Use HuggingFace's sentence transformer model [all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) to generate embeddings\n",
    "2. Store and query vector embeddings using pgvector in Aurora PostgreSQL  \n",
    "3. Implement semantic search using LangChain's vector store capabilities\n",
    "4. Calculate similarity scores between text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install required Python libraries for the setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sentencepiece for tokenization (required by transformer models)\n",
    "!conda install -c conda-forge sentencepiece -y > /dev/null 2>&1\n",
    "print(\"‚úÖ Sentencepiece installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "# Core dependencies\n",
    "langchain==0.2.16\n",
    "langchain-community==0.2.17\n",
    "langchain-postgres==0.0.15\n",
    "langchain-huggingface==0.0.3\n",
    "psycopg2-binary==2.9.10\n",
    "pgvector==0.2.5\n",
    "python-dotenv==1.0.0\n",
    "sentence-transformers>=2.5.0\n",
    "huggingface-hub>=0.20.0\n",
    "numpy==1.26.4\n",
    "pandas==1.5.3\n",
    "torch\n",
    "transformers>=4.36.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all packages with upgrade flag for numpy\n",
    "!pip install --upgrade numpy==1.26.4 -q\n",
    "!pip install -r requirements.txt -q\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment and Import Libraries\n",
    "\n",
    "Import required libraries and initialize the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and setup environment\n",
    "import warnings\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "# Import core libraries\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Use the new langchain-huggingface package to avoid deprecation warning\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize embeddings with the new import\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(f\"üìä Using embedding model: all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Database Connection\n",
    "\n",
    "Set up connection parameters for Aurora PostgreSQL with pgvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection configuration\n",
    "import os\n",
    "\n",
    "DB_HOST = os.getenv('PGVECTOR_HOST', 'localhost')\n",
    "DB_PORT = os.getenv('PGVECTOR_PORT', '5432')\n",
    "DB_NAME = os.getenv('PGVECTOR_DATABASE', 'postgres')\n",
    "DB_USER = os.getenv('PGVECTOR_USER', 'postgres')\n",
    "DB_PASSWORD = os.getenv('PGVECTOR_PASSWORD', 'password')\n",
    "DB_DRIVER = 'psycopg2'\n",
    "\n",
    "# Build connection string\n",
    "CONNECTION_STRING = f\"postgresql+{DB_DRIVER}://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "\n",
    "# Collection name for vector store\n",
    "COLLECTION_NAME = \"hotel_reviews_langchain\"\n",
    "\n",
    "# Display configuration (masking password)\n",
    "display_connection = CONNECTION_STRING.replace(DB_PASSWORD, \"****\")\n",
    "print(f\"üìä Database Configuration:\")\n",
    "print(f\"   Host: {DB_HOST}\")\n",
    "print(f\"   Database: {DB_NAME}\")\n",
    "print(f\"   Collection: {COLLECTION_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Load hotel reviews data from CSV file or create sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check for data file\n",
    "data_file = './data/fictitious_hotel_reviews_trimmed_500.csv'\n",
    "if not os.path.exists(data_file):\n",
    "    print(\"‚ö†Ô∏è Data file not found. Creating sample data...\")\n",
    "    os.makedirs('./data', exist_ok=True)\n",
    "    \n",
    "    # Create diverse sample hotel reviews\n",
    "    sample_reviews = [\n",
    "        \"Excellent service and beautiful rooms. The staff was very helpful and the breakfast was amazing.\",\n",
    "        \"Great location near the beach. Pool area was fantastic! Very family friendly.\",\n",
    "        \"Amazing mountain views. Perfect for a peaceful getaway. Very quiet and relaxing.\",\n",
    "        \"Convenient location but rooms were a bit small. Good value for money though.\",\n",
    "        \"Beautiful lake views. Restaurant food was delicious. Will definitely come back.\",\n",
    "        \"The room was spotlessly clean and the bed was very comfortable. Great night's sleep.\",\n",
    "        \"Staff went above and beyond to help us. Really appreciated their hospitality.\",\n",
    "        \"Loved the spa facilities. Very relaxing atmosphere throughout the hotel.\",\n",
    "        \"Business center was well equipped. Perfect for work trips.\",\n",
    "        \"Kids loved the pool and game room. Great family vacation spot.\",\n",
    "        \"Room service was prompt and the food quality was excellent.\",\n",
    "        \"The concierge helped us plan our entire itinerary. Very knowledgeable.\",\n",
    "        \"Gym facilities were modern and well-maintained. Appreciated the 24-hour access.\",\n",
    "        \"The rooftop bar had amazing views of the city. Great cocktails too.\",\n",
    "        \"Breakfast buffet had lots of options including healthy choices.\",\n",
    "        \"Location was perfect - walking distance to all major attractions.\",\n",
    "        \"The hotel shuttle service to the airport was very convenient.\",\n",
    "        \"Loved the boutique feel of this hotel. Very unique decor.\",\n",
    "        \"Conference facilities were excellent for our business meeting.\",\n",
    "        \"The pet-friendly policy was great. Our dog was well taken care of.\"\n",
    "    ]\n",
    "    \n",
    "    # Create DataFrame with more reviews\n",
    "    import random\n",
    "    all_reviews = []\n",
    "    for _ in range(100):\n",
    "        all_reviews.append(random.choice(sample_reviews))\n",
    "    \n",
    "    sample_data = pd.DataFrame({'comments': all_reviews})\n",
    "    data_file = './data/hotel_reviews.csv'\n",
    "    sample_data.to_csv(data_file, index=False)\n",
    "    print(f\"‚úÖ Created sample data file with {len(sample_data)} reviews\")\n",
    "\n",
    "# Load data using LangChain's CSVLoader\n",
    "loader = CSVLoader(\n",
    "    file_path=data_file,\n",
    "    encoding='utf-8',\n",
    "    csv_args={'delimiter': ','}\n",
    ")\n",
    "data = loader.load()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(data)} documents\")\n",
    "print(f\"\\nFirst 3 reviews:\")\n",
    "for i, doc in enumerate(data[:3], 1):\n",
    "    print(f\"\\n{i}. {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Documents into Chunks\n",
    "\n",
    "Split documents into smaller chunks for better retrieval performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Split documents into chunks\n",
    "docs = text_splitter.split_documents(data)\n",
    "\n",
    "print(f\"‚úÖ Split {len(data)} documents into {len(docs)} chunks\")\n",
    "print(f\"Average chunk size: {sum(len(d.page_content) for d in docs) / len(docs):.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store and Index Documents\n",
    "\n",
    "Create pgvector collection and store document embeddings in Aurora PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PGVector instance and store documents\n",
    "print(\"üöÄ Creating vector store collection...\")\n",
    "print(\"‚è≥ This may take a minute...\")\n",
    "\n",
    "try:\n",
    "    db = PGVector.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        connection=CONNECTION_STRING,\n",
    "        pre_delete_collection=True  # Clean start - delete if exists\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Vector store created successfully!\")\n",
    "    print(f\"üìä Collection: {COLLECTION_NAME}\")\n",
    "    print(f\"üìù Documents indexed: {len(docs)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating vector store: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check database connection settings in .env file\")\n",
    "    print(\"2. Ensure pgvector extension is installed: CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    print(\"3. Verify database user has necessary permissions\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search with Score\n",
    "\n",
    "Perform similarity search and retrieve documents with their similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search query\n",
    "query = \"What do some of the positive reviews say?\"\n",
    "\n",
    "# Perform similarity search with scores\n",
    "docs_with_score = db.similarity_search_with_score(query, k=5)\n",
    "\n",
    "print(f\"üîç Query: '{query}'\")\n",
    "print(f\"üìä Found {len(docs_with_score)} matches\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display search results with scores\n",
    "for i, (doc, score) in enumerate(docs_with_score, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"üìà Similarity Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Content: {doc.page_content[:200]}...\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Retriever for Chain Integration\n",
    "\n",
    "Use cosine distance strategy for similarity calculations and create a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_postgres.vectorstores import DistanceStrategy\n",
    "\n",
    "# Create a new vector store with cosine distance strategy\n",
    "db_cosine = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection=CONNECTION_STRING,\n",
    "    distance_strategy=DistanceStrategy.COSINE  # Use cosine similarity\n",
    ")\n",
    "\n",
    "# Create a retriever for use in chains\n",
    "retriever = db_cosine.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}  # Return top 4 results\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created retriever with cosine similarity\")\n",
    "print(\"üìä Retriever will return top 4 most similar documents\")\n",
    "\n",
    "# Test the retriever\n",
    "test_query = 'excellent service'\n",
    "retrieved_docs = retriever.invoke(test_query)\n",
    "\n",
    "print(f\"\\nüîç Test Query: '{test_query}'\")\n",
    "print(f\"üìä Retrieved {len(retrieved_docs)} documents\\n\")\n",
    "\n",
    "# Display first two results\n",
    "for i, doc in enumerate(retrieved_docs[:2], 1):\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"{doc.page_content[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Search Methods\n",
    "\n",
    "Explore different search methods available in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic similarity search (without scores)\n",
    "print(\"1Ô∏è‚É£ Basic Similarity Search:\")\n",
    "basic_results = db.similarity_search(\"excellent service\", k=3)\n",
    "print(f\"Found {len(basic_results)} results\")\n",
    "\n",
    "if basic_results:\n",
    "    print(f\"Sample: {basic_results[0].page_content[:150]}...\\n\")\n",
    "\n",
    "# 2. Maximum Marginal Relevance (MMR) search\n",
    "# Returns diverse results by balancing relevance and diversity\n",
    "print(\"2Ô∏è‚É£ MMR Search (for diverse results):\")\n",
    "mmr_results = db.max_marginal_relevance_search(\n",
    "    \"hotel amenities\",\n",
    "    k=3,\n",
    "    fetch_k=10,  # Fetch more candidates for diversity\n",
    "    lambda_mult=0.5  # Balance between relevance and diversity\n",
    ")\n",
    "print(f\"Found {len(mmr_results)} diverse results\")\n",
    "\n",
    "for i, doc in enumerate(mmr_results, 1):\n",
    "    print(f\"  {i}. {doc.page_content[:100]}...\")\n",
    "\n",
    "print()\n",
    "\n",
    "# 3. Test different query types\n",
    "print(\"3Ô∏è‚É£ Testing different query types:\")\n",
    "test_queries = [\n",
    "    \"breakfast quality\",\n",
    "    \"room cleanliness\", \n",
    "    \"staff friendliness\"\n",
    "]\n",
    "\n",
    "for test_query in test_queries:\n",
    "    results = db.similarity_search_with_score(test_query, k=1)\n",
    "    if results:\n",
    "        doc, score = results[0]\n",
    "        print(f\"  Query: '{test_query}' - Best match (score: {score:.3f})\")\n",
    "        print(f\"    ‚Üí {doc.page_content[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated:\n",
    "\n",
    "‚úÖ **Vector Embeddings**: Generated 768-dimensional embeddings using all-mpnet-base-v2  \n",
    "‚úÖ **pgvector Storage**: Stored embeddings in Aurora PostgreSQL with pgvector extension  \n",
    "‚úÖ **Similarity Search**: Retrieved semantically similar documents  \n",
    "‚úÖ **Score Calculation**: Computed cosine similarity scores  \n",
    "‚úÖ **LangChain Integration**: Created retrievers for use in chains  \n",
    "\n",
    "### Key Technologies Used:\n",
    "- **LangChain**: Framework for building applications with LLMs\n",
    "- **pgvector**: PostgreSQL extension for vector similarity search\n",
    "- **Sentence Transformers**: State-of-the-art embeddings\n",
    "- **Aurora PostgreSQL**: Managed database service\n",
    "\n",
    "### Next Steps:\n",
    "- Scale to larger datasets\n",
    "- Integrate with LLMs for question-answering (RAG)\n",
    "- Optimize with IVFFlat or HNSW indexes for better performance\n",
    "- Experiment with different embedding models\n",
    "- Add metadata filtering for more precise searches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
