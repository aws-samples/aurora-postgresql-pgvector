# ğŸ¤– Enterprise RAG Question-Answering System

Build an enterprise-ready Retrieval Augmented Generation (RAG) application leveraging Amazon Web Services and open-source technologies. This implementation creates an intelligent question-answering system that combines the power of vector databases with state-of-the-art language models.

## ğŸ¯ Overview

This solution demonstrates the implementation of a production-ready RAG system using:

- ğŸš€ Amazon Bedrock for accessing foundation models
- ğŸ“Š pgvector extension on Amazon Aurora PostgreSQL for vector operations
- ğŸ§  Anthropic's Claude for advanced language understanding
- ğŸ’« Titan Text for generating high-quality text embeddings
- ğŸ”— LangChain for orchestrating AI components
- ğŸ–¥ï¸ Streamlit for creating an intuitive user interface

## ğŸ—ï¸ Architecture

![Architecture](static/RAG_APG.png)

## âš™ï¸ System Workflow

Our RAG implementation follows a sophisticated pipeline to deliver accurate answers:

1. **Document Ingestion** ğŸ“„
   - Processes PDF documents through advanced text extraction
   - Maintains document structure and metadata

2. **Semantic Processing** ğŸ”„
   - Implements intelligent text chunking algorithms
   - Preserves context across document segments

3. **Vector Embedding** ğŸ¯
   - Utilizes Amazon Bedrock's Titan Text for generating embeddings
   - Creates high-dimensional vector representations of content

4. **Query Processing** ğŸ’­
   - Accepts natural language questions
   - Converts queries into compatible vector representations

5. **Context Retrieval** ğŸ”
   - Performs semantic similarity matching
   - Identifies relevant document segments

6. **Answer Generation** âœ¨
   - Leverages Anthropic's Claude for response synthesis
   - Ensures responses are grounded in source documents

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9 or higher
- AWS account with Bedrock access
- Amazon Aurora PostgreSQL cluster
- Git

### Installation

1. Clone the repository:
   ```bash
   git clone [repository-url]
   cd [repository-name]
   ```

2. Create and activate a virtual environment:
   ```bash
   python3.9 -m venv env
   source env/bin/activate
   ```

3. Configure environment variables:
   ```bash
   # Create .env file with the following structure
   PGVECTOR_DRIVER='psycopg2'
   PGVECTOR_USER='<username>'
   PGVECTOR_PASSWORD='<password>'
   PGVECTOR_HOST='<aurora-cluster-endpoint>'
   PGVECTOR_PORT=5432
   PGVECTOR_DATABASE='<database-name>'
   ```

4. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Database Setup

1. Connect to your Aurora PostgreSQL cluster
2. Enable the pgvector extension:
   ```sql
   CREATE EXTENSION vector;
   ```

## ğŸ’» Usage

1. Launch the application:
   ```bash
   streamlit run app.py
   ```

2. Navigate to the web interface in your browser
3. Upload PDF documents through the provided interface
4. Start asking questions about your documents

## ğŸ”’ Security Considerations

- Implement appropriate IAM roles and permissions
- Secure database connections using SSL/TLS
- Follow AWS security best practices for Bedrock access
- Properly handle sensitive information in environment variables

## ğŸ“ˆ Performance Optimization

- Utilize connection pooling for database operations
- Implement caching strategies where appropriate
- Configure proper chunk sizes for optimal retrieval
- Monitor and adjust embedding dimensions based on requirements

## ğŸ¤ Contributing

This project is maintained for educational purposes and demonstrates AWS best practices. While we don't accept direct contributions, we encourage:

- Creating issues for bugs or suggested improvements
- Forking the repository for personal customization
- Sharing your experiences and optimizations

## ğŸ“ License

This project is licensed under the [MIT-0 License](https://spdx.org/licenses/MIT-0.html) - see the LICENSE file for details.
